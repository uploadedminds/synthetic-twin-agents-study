{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8d0a413-95ca-425a-8841-6c11283ed6e9",
   "metadata": {},
   "source": [
    "<h2>Data cleaning & validation</h2>\n",
    "<h3>1. Detect completion time outliers beyond 3 SDs from the mean</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a1f8cd-9d36-4d63-b87f-ba923e4447e7",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def detect_outlier_participants(data):\n",
    "    data['StartDate'] = pd.to_datetime(data['StartDate'])\n",
    "    data['EndDate'] = pd.to_datetime(data['EndDate'])\n",
    "    \n",
    "    # Calculate survey duration in seconds\n",
    "    data['Duration'] = (data['EndDate'] - data['StartDate']).dt.total_seconds()\n",
    "    \n",
    "    # Calculate mean and standard deviation of survey times\n",
    "    mean_duration = data['Duration'].mean()\n",
    "    std_duration = data['Duration'].std()\n",
    "\n",
    "    # Define thresholds for outliers\n",
    "    lower_threshold = mean_duration - 3 * std_duration\n",
    "    upper_threshold = mean_duration + 3 * std_duration\n",
    "    \n",
    "    # Identify participants below and above thresholds\n",
    "    below_3_std = data[data['Duration'] < lower_threshold]\n",
    "    above_3_std = data[data['Duration'] > upper_threshold]\n",
    "    \n",
    "    # Filter out outliers from the original DataFrame\n",
    "    participants_within_3_std = data[(data['Duration'] >= lower_threshold) & (data['Duration'] <= upper_threshold)]\n",
    "\n",
    "    print(mean_duration)\n",
    "    print(f'beloow: {len(df)}, after: {len(participants_within_3_std)}')\n",
    "\n",
    "    return below_3_std, above_3_std, participants_within_3_std\n",
    "\n",
    "\n",
    "df = pd.read_csv('../../data/prolific_participants_dataset.csv')\n",
    "\n",
    "below_3_std, above_3_std, participants_within_3_std = detect_outlier_participants(df)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ea1e4f-cd5e-45eb-b448-35d2a7ed7772",
   "metadata": {},
   "source": [
    "<h3>2. Detect participants failing multiple attention checks</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045f2355-10e3-433a-adbf-9ad5664d1ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_participants_with_multiple_failed_attention_checks(df):\n",
    "    checks = {\n",
    "        'pq_attention_check_1': 5, \n",
    "        'pq_attention_check_2': 2, \n",
    "        'p_3_agree_att_check': 2, \n",
    "        'seriousness_check': 2\n",
    "    }\n",
    "\n",
    "    df = df.copy()\n",
    "    df['failed_checks'] = df[list(checks)].apply(lambda row: sum(row[col] != val for col, val in checks.items()), axis=1)\n",
    "    failed_participants = df[df['failed_checks'] > 1]\n",
    "\n",
    "    return failed_participants\n",
    "\n",
    "participants = detect_participants_with_multiple_failed_attention_checks(participants_within_3_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5270bf98-f930-401b-983a-65fa765afc10",
   "metadata": {},
   "source": [
    "<h3>3. Exclude participants failing attention checks and suspected bots <a href=\"https://www.qualtrics.com/support/survey-platform/survey-module/survey-checker/fraud-detection/#BotDetection\">bots</a> (Q_RecaptchaScore >= 0.5)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1750ca16-e94f-4f24-8f6a-9e988e198511",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def exclude_failed_attention_checks_and_bots(df):\n",
    "    # Define correct attention check responses\n",
    "    passed_checks = (\n",
    "        (df['pq_attention_check_1'] == 5) & \n",
    "        (df['pq_attention_check_2'] == 2) & \n",
    "        (df['p_3_agree_att_check'] == 2) &\n",
    "        (df['seriousness_check'] == 2) & \n",
    "        (df['Q_RecaptchaScore'] >= 0.5)\n",
    "    )\n",
    "    \n",
    "    return df[passed_checks].copy()\n",
    "\n",
    "num_passed_captcha = (participants_within_3_std['Q_RecaptchaScore'] >= 0.5).sum()\n",
    "print(f\"Number of participants who passed CAPTCHA: {num_passed_captcha}\")\n",
    "\n",
    "num_likely_bots = (participants_within_3_std['Q_RecaptchaScore'] < 0.5).sum()\n",
    "print(f\"Number of likely bots (reCAPTCHA score < 0.5): {num_likely_bots}\")\n",
    "\n",
    "df_filtered = exclude_failed_attention_checks_and_bots(participants_within_3_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0775e807-9790-4763-8a67-c90f44adb4cb",
   "metadata": {},
   "source": [
    "<h1>Analysis</h1>\n",
    "<h3>1. Participants Demographics</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b329a3-9199-42e5-ac20-55103aa4d2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")  \n",
    "\n",
    "from utils.mappings import MAPPINGS\n",
    "\n",
    "\n",
    "def summarize_us_participants(df):\n",
    "    total_n = len(df)\n",
    "    mean_age = round(df['age'].mean(), 2)\n",
    "    std_age = round(df['age'].std(), 2)\n",
    "    \n",
    "    gender_counts = df['gender'].map(MAPPINGS['gender']).value_counts()\n",
    "    female = gender_counts.get('Female', 0)\n",
    "    male = gender_counts.get('Male', 0)\n",
    "    non_binary = gender_counts.get('Non-binary / third gender', 0)\n",
    "    prefer_not_to_say = gender_counts.get('Prefer not to say', 0)\n",
    "\n",
    "    return {\n",
    "        'Country': 'USA',\n",
    "        'N': total_n,\n",
    "        'M': mean_age,\n",
    "        'SD': std_age,\n",
    "        'Female': female,\n",
    "        'Male': male,\n",
    "        'Non-binary / third gender': non_binary,\n",
    "        'Prefer not to answer': prefer_not_to_say\n",
    "    }\n",
    "\n",
    "# Apply to both datasets\n",
    "summary_all = summarize_us_participants(df)\n",
    "summary_filtered = summarize_us_participants(df_filtered)\n",
    "\n",
    "us_summary_table = pd.DataFrame([\n",
    "    {'Group': 'All participants', **summary_all},\n",
    "    {'Group': 'Participants eligible for analyses after exclusions', **summary_filtered}\n",
    "])\n",
    "\n",
    "us_summary_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db71cad0-b551-48d7-a219-c2e3b38ef7ce",
   "metadata": {},
   "source": [
    "<h3>2. Calculat Personality Traits (Mini-IPIP) Scores</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babcca5b-db46-4532-8a6f-a218b1ba2731",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_mini_ipip_scores(dataframe):\n",
    "    traits = {\n",
    "        \"extraversion\": [\"pq_1\", \"pq_6_reverse_score\", \"pq_11\", \"pq_16_reverse_score\"],\n",
    "        \"agreeableness\": [\"pq_2\", \"pq_7_reverse_score\", \"pq_12\", \"pq_17_reverse_score\"],\n",
    "        \"conscientiousness\": [\"pq_3\", \"pq_8_reverse_score\", \"pq_13\", \"pq_18_reverse_score\"],\n",
    "        \"neuroticism\": [\"pq_4\", \"pq_9_reverse_score\", \"pq_14\", \"pq_19_reverse_score\"],\n",
    "        \"openness\": [\"pq_5\", \"pq_10_reverse_score\", \"pq_15_reverse_score\", \"pq_20_reverse_score\"]\n",
    "    }\n",
    "\n",
    "    df = dataframe.copy()\n",
    "\n",
    "    # Reverse scoring logic: Apply 6 - response for specific items\n",
    "    for trait, questions in traits.items():\n",
    "        for q in questions:\n",
    "            if \"reverse_score\" in q:\n",
    "                df[q] = 6 - df[q]\n",
    "\n",
    "    # Calculate the mean score for each trait (1-5 scale)\n",
    "    for trait, questions in traits.items():\n",
    "        # Validate responses are within 1-5 range\n",
    "        for q in questions:\n",
    "            if not df[q].between(1, 5).all():\n",
    "                print(f\"Warning: Found values outside 1-5 range in {q}\")\n",
    "                df.loc[~df[q].between(1, 5), q] = np.nan\n",
    "        \n",
    "        # Calculate mean score\n",
    "        df[f\"{trait}_score\"] = df[questions].mean(axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def drop_invalid_trait_scores(df):\n",
    "    columns_to_drop = [\n",
    "        \"intellectImagination_score\",\n",
    "        \"extraversion_score\",\n",
    "        \"agreeableness_score\",\n",
    "        \"conscientiousness_score\",\n",
    "        \"neuroticism_score\"\n",
    "    ]\n",
    "\n",
    "    df = df.drop(columns=columns_to_drop, errors='ignore')\n",
    "    return df\n",
    "\n",
    "def validate_scores(df):\n",
    "    traits = [\"extraversion\", \"agreeableness\", \"conscientiousness\", \n",
    "              \"neuroticism\", \"openness\"]\n",
    "    \n",
    "    valid = True\n",
    "    for trait in traits:\n",
    "        score_col = f\"{trait}_score\"\n",
    "        if not df[score_col].between(1, 5).all():\n",
    "            print(f\"Error: {trait} scores outside valid range (1-5)\")\n",
    "            valid = False\n",
    "        \n",
    "        if df[score_col].isna().any():\n",
    "            print(f\"Warning: Found missing values in {trait} scores\")\n",
    "            valid = False\n",
    "    \n",
    "    return valid\n",
    "\n",
    "#calcualate new scores\n",
    "df_filtered = calculate_mini_ipip_scores(drop_invalid_trait_scores(df_filtered.copy()))\n",
    "\n",
    "#validate scores\n",
    "if not validate_scores(df_filtered):\n",
    "    raise ValueError(\"Score validation failed! Please check the input data for inconsistencies.\")\n",
    "\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c3ce08-045d-4645-ad09-a21575e9c294",
   "metadata": {},
   "source": [
    "<h3>3. Evaluate internal consistency (Cronbach's Alpha) of Mini-IPIP responses</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbf0cf5-0775-426f-bbad-fafad7ab2a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg\n",
    "\n",
    "def calculate_mini_ipip_cronbach_alphas(df):\n",
    "    alphas = {}\n",
    "    \n",
    "    trait_items = {\n",
    "        \"Extraversion\": ['pq_1', 'pq_6_reverse_score', 'pq_11', 'pq_16_reverse_score'],\n",
    "        \"Agreeableness\": ['pq_2', 'pq_7_reverse_score', 'pq_12', 'pq_17_reverse_score'],\n",
    "        \"Conscientiousness\": ['pq_3', 'pq_8_reverse_score', 'pq_13', 'pq_18_reverse_score'],\n",
    "        \"Neuroticism\": ['pq_4', 'pq_9_reverse_score', 'pq_14', 'pq_19_reverse_score'],\n",
    "        \"Openness\": ['pq_5', 'pq_10_reverse_score', 'pq_15_reverse_score', 'pq_20_reverse_score']\n",
    "    }\n",
    "\n",
    "    for trait, item_columns in trait_items.items():\n",
    "        # Subset the DataFrame to include only the columns of interest\n",
    "        subset = df[item_columns]\n",
    "        \n",
    "        # Calculate Cronbach's alpha\n",
    "        alpha = pg.cronbach_alpha(data=subset)\n",
    "        \n",
    "        # Store the alpha value\n",
    "        alphas[trait] = alpha[0]\n",
    "\n",
    "    return alphas\n",
    "\n",
    "# Calculate Cronbach's alpha for all traits\n",
    "alphas = calculate_mini_ipip_cronbach_alphas(df_filtered)\n",
    "\n",
    "for trait, alpha in alphas.items():\n",
    "    print(f\"Cronbach's alpha for {trait}: {alpha:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9df156a-aad2-4229-9fd2-ea2a67753384",
   "metadata": {},
   "source": [
    "<h3>4. Evaluate internal consistency (Cronbach's Alpha) for Advertisement Effectiveness Scores</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a1091a-1663-4a89-a5df-b11a7174530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg\n",
    "\n",
    "def calculate_aes_cronbach_alphas(df):\n",
    "    alphas = {}    \n",
    "\n",
    "    trait_items = {\n",
    "        \"Product 1 - Openness\": ['p_1_openness_item_1', 'p_1_openness_item_2', 'p_1_openness_item_3', 'p_1_openness_item_4', 'p_1_openness_item_5', 'p_1_openness_item_6'],\n",
    "        \"Product 1 - Conscientiousness\": ['p_1_consc_item_1', 'p_1_consc_item_2', 'p_1_consc_item_3', 'p_1_consc_item_4', 'p_1_consc_item_5', 'p_1_consc_item_6'],\n",
    "        \"Product 1 - Extraversion\": ['p_1_extr_item_1', 'p_1_extr_item_2', 'p_1_extr_item_3', 'p_1_extr_item_4', 'p_1_extr_item_5', 'p_1_extr_item_6'],\n",
    "        \"Product 1 - Agreeableness\": ['p_1_agree_item_1', 'p_1_agree_item_2', 'p_1_agree_item_3', 'p_1_agree_item_4', 'p_1_agree_item_5', 'p_1_agree_item_6'],\n",
    "        \"Product 1 - Neuroticism\": ['p_1_neuro_item_1', 'p_1_neuro_item_2', 'p_1_neuro_item_3', 'p_1_neuro_item_4', 'p_1_neuro_item_5', 'p_1_neuro_item_6'],\n",
    "        \n",
    "        \"Product 2 - Openness\": ['p_2_openness_item_1', 'p_2_openness_item_2', 'p_2_openness_item_3', 'p_2_openness_item_4', 'p_2_openness_item_5', 'p_2_openness_item_6'],\n",
    "        \"Product 2 - Conscientiousness\": ['p_2_consc_item_1', 'p_2_consc_item_2', 'p_2_consc_item_3', 'p_2_consc_item_4', 'p_2_consc_item_5', 'p_2_consc_item_6'],\n",
    "        \"Product 2 - Extraversion\": ['p_2_extr_item_1', 'p_2_extr_item_2', 'p_2_extr_item_3', 'p_2_extr_item_4', 'p_2_extr_item_5', 'p_2_extr_item_6'],\n",
    "        \"Product 2 - Agreeableness\": ['p_2_agree_item_1', 'p_2_agree_item_2', 'p_2_agree_item_3', 'p_2_agree_item_4', 'p_2_agree_item_5', 'p_2_agree_item_6'],\n",
    "        \"Product 2 - Neuroticism\": ['p_2_neuro_item_1', 'p_2_neuro_item_2', 'p_2_neuro_item_3', 'p_2_neuro_item_4', 'p_2_neuro_item_5', 'p_2_neuro_item_6'],\n",
    "        \n",
    "        \"Product 3 - Openness\": ['p_3_openness_item_1', 'p_3_openness_item_2', 'p_3_openness_item_3', 'p_3_openness_item_4', 'p_3_openness_item_5', 'p_3_openness_item_6'],\n",
    "        \"Product 3 - Conscientiousness\": ['p_3_consc_item_1', 'p_3_consc_item_2', 'p_3_consc_item_3', 'p_3_consc_item_4', 'p_3_consc_item_5', 'p_3_consc_item_6'],\n",
    "        \"Product 3 - Extraversion\": ['p_3_extr_item_1', 'p_3_extr_item_2', 'p_3_extr_item_3', 'p_3_extr_item_4', 'p_3_extr_item_5', 'p_3_extr_item_6'],\n",
    "        \"Product 3 - Agreeableness\": ['p_3_agree_item_1', 'p_3_agree_item_2', 'p_3_agree_item_3', 'p_3_agree_item_4', 'p_3_agree_item_5', 'p_3_agree_item_6'],\n",
    "        \"Product 3 - Neuroticism\": ['p_3_neuro_item_1', 'p_3_neuro_item_2', 'p_3_neuro_item_3', 'p_3_neuro_item_4', 'p_3_neuro_item_5', 'p_3_neuro_item_6'],\n",
    "    }\n",
    "\n",
    "    for trait, item_columns in trait_items.items():\n",
    "        # Subset the DataFrame to include only the columns of interest\n",
    "        subset = df[item_columns]\n",
    "        \n",
    "        # Check if all required columns are in the DataFrame\n",
    "        if not all(col in df.columns for col in item_columns):\n",
    "            print(\"ALERT!!!\")\n",
    "            alphas[trait] = None  # Assign None if any column is missing\n",
    "            continue\n",
    "\n",
    "        # Calculate Cronbach's alpha using pingouin\n",
    "        alpha = pg.cronbach_alpha(data=subset)\n",
    "        \n",
    "        # Store the alpha value in the dictionary\n",
    "        alphas[trait] = alpha[0]\n",
    "\n",
    "    return alphas\n",
    "\n",
    "\n",
    "\n",
    "alphas = calculate_aes_cronbach_alphas(df_filtered)\n",
    "\n",
    "for product, alpha in alphas.items():\n",
    "    if alpha is not None:\n",
    "        print(f\"Cronbach's Alpha for {product}: {alpha:.3f}\")\n",
    "    else:\n",
    "        print(f\"Cronbach's Alpha for {product}: Data missing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5364e854-96e0-4163-bdf0-ecf570e8f408",
   "metadata": {},
   "source": [
    "<h3>5. Aggregate Advertisement Effectiveness Scores (AES) scores to derive Dependent Variables: AES by trait and product</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10d1faf-548c-4bc8-bc3d-0c76186f6402",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "def calculate_raw_and_residualized_aes(dataframe):\n",
    "    product_numbers = [1, 2, 3]\n",
    "    \n",
    "    traits = {\n",
    "        \"openness\": \"openness\",\n",
    "        \"conscientiousness\": \"consc\",\n",
    "        \"extraversion\": \"extr\",\n",
    "        \"agreeableness\": \"agree\",\n",
    "        \"neuroticism\": \"neuro\"\n",
    "    }\n",
    "\n",
    "    for product_num in product_numbers:\n",
    "        # Dictionary to store raw AES columns for each trait for the current product\n",
    "        aes_columns = {}\n",
    "\n",
    "        # Step 1: Calculate Raw AES\n",
    "        for trait_name, trait_prefix in traits.items():\n",
    "            # Find all relevant item columns for this product and trait\n",
    "            target_columns = [\n",
    "                col for col in dataframe.columns\n",
    "                if col.startswith(f\"p_{product_num}_{trait_prefix}_item_\")\n",
    "            ]\n",
    "            \n",
    "            if target_columns:\n",
    "                # Calculate raw AES as the mean of relevant columns\n",
    "                dataframe[f\"aes_{product_num}_{trait_name}\"] = dataframe[target_columns].mean(axis=1, skipna=True)\n",
    "                aes_columns[trait_name] = dataframe[f\"aes_{product_num}_{trait_name}\"]\n",
    "            else:\n",
    "                print(f\"No valid columns found for product {product_num}, trait {trait_name}!\")\n",
    "\n",
    "        # Step 2: Calculate Residualized AES\n",
    "        for target_trait, aes_target in aes_columns.items():\n",
    "            # Use raw AES scores of other traits as predictors\n",
    "            predictors = [\n",
    "                aes_columns[other_trait]\n",
    "                for other_trait in traits.keys()\n",
    "                if other_trait != target_trait and other_trait in aes_columns\n",
    "            ]\n",
    "\n",
    "            if predictors:\n",
    "                # Stack predictors into a matrix\n",
    "                predictors_matrix = np.column_stack(predictors)\n",
    "                \n",
    "                # Perform regression to calculate residuals\n",
    "                regression_model = LinearRegression()\n",
    "                regression_model.fit(predictors_matrix, aes_target)\n",
    "                residuals = aes_target - regression_model.predict(predictors_matrix)\n",
    "                \n",
    "                # Save residualized AES\n",
    "                dataframe[f\"aes_resd_{product_num}_{target_trait}\"] = residuals\n",
    "            else:\n",
    "                # If no predictors are available, retain raw AES\n",
    "                dataframe[f\"aes_{product_num}_{target_trait}\"] = aes_target\n",
    "                print(f\"Could not residualize AES for product {product_num}, trait {target_trait} due to missing predictors.\")\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "df_filtered = calculate_raw_and_residualized_aes(df_filtered.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f1d99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.to_csv('../../data/filtered_participants_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aa530a-3e84-463c-8aae-d85423cd023b",
   "metadata": {},
   "source": [
    "<h3>6. Regression Analysis: using Big Five personality traits to predict respondents’ AES scores</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f637b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def perform_regression_on_personality(df, aes_type='raw'):\n",
    "    # Personality trait columns (predictors)\n",
    "    traits_cols = [\n",
    "        'extraversion_score',\n",
    "        'agreeableness_score',\n",
    "        'conscientiousness_score',\n",
    "        'neuroticism_score',\n",
    "        'openness_score'\n",
    "    ]\n",
    "\n",
    "    if aes_type == 'raw':\n",
    "        aes_sufix = 'aes'\n",
    "    elif aes_type == 'resd':\n",
    "        aes_sufix = 'aes_resd'\n",
    "\n",
    "    # AES columns grouped by product\n",
    "    product_aes_cols = {\n",
    "        \"p1\": [f'{aes_sufix}_1_extraversion', f'{aes_sufix}_1_agreeableness', f'{aes_sufix}_1_conscientiousness', f'{aes_sufix}_1_neuroticism', f'{aes_sufix}_1_openness'],\n",
    "        \"p2\": [f'{aes_sufix}_2_extraversion', f'{aes_sufix}_2_agreeableness', f'{aes_sufix}_2_conscientiousness', f'{aes_sufix}_2_neuroticism', f'{aes_sufix}_2_openness'],\n",
    "        \"p3\": [f'{aes_sufix}_3_extraversion', f'{aes_sufix}_3_agreeableness', f'{aes_sufix}_3_conscientiousness', f'{aes_sufix}_3_neuroticism', f'{aes_sufix}_3_openness']\n",
    "    }\n",
    "\n",
    "    results_dict = {}\n",
    "\n",
    "    for product, aes_cols in product_aes_cols.items():\n",
    "        # Create a results DataFrame for this product\n",
    "        results = pd.DataFrame(index=traits_cols, columns=aes_cols)\n",
    "\n",
    "        for aes_col in aes_cols:\n",
    "            # Standardize predictors (traits) and outcome (AES)\n",
    "            scaler = StandardScaler()\n",
    "            X = scaler.fit_transform(df[traits_cols])\n",
    "            y = scaler.fit_transform(df[[aes_col]]).flatten()\n",
    "\n",
    "            # Add constant to predictors\n",
    "            X = sm.add_constant(X)\n",
    "\n",
    "            # Fit regression model\n",
    "            model = sm.OLS(y, X).fit()\n",
    "\n",
    "            # Extract coefficients and p-values (skip constant)\n",
    "            coefficients = model.params[1:]\n",
    "            p_values = model.pvalues[1:]\n",
    "\n",
    "            # Store results as standardized beta coefficients with p-values\n",
    "            results[aes_col] = [\n",
    "                f\"{0.00 if round(coeff, 2) == 0 else coeff:.2f} ({pval:.4f})\"\n",
    "                for coeff, pval in zip(coefficients, p_values)\n",
    "            ]\n",
    "\n",
    "        # Save this product's results\n",
    "        results_dict[product] = results\n",
    "\n",
    "    # Return results for all three products\n",
    "    return results_dict[\"p1\"], results_dict[\"p2\"], results_dict[\"p3\"]\n",
    "\n",
    "\n",
    "# Raw AES\n",
    "raw_results_p1, raw_results_p2, raw_results_p3 = perform_regression_on_personality(df_filtered, aes_type='raw')\n",
    "\n",
    "print(\"Human Participants: Regression Coefficient Matrix – P1: Cabin luggage\")\n",
    "display(raw_results_p1)\n",
    "print(\"Human Participants: Regression Coefficient – P2: Packing Cubes\")\n",
    "display(raw_results_p2)\n",
    "print(\"Human Participants: Regression Coefficient – P3:Water Bottle\")\n",
    "display(raw_results_p3)\n",
    "\n",
    "# # Residualized AES\n",
    "resd_results_p1, resd_results_p2, resd_results_p3 = perform_regression_on_personality(df_filtered, aes_type='resd')\n",
    "\n",
    "print(\"Human Participants: Regression Coefficient Matrix – P1: Cabin luggage (Residualized AES)\")\n",
    "display(resd_results_p1)\n",
    "print(\"Human Participants: Regression Coefficient – P2: Packing Cubes (Residualized AES)\")\n",
    "display(resd_results_p2)\n",
    "print(\"Human Participants: Regression Coefficient – P3:Water Bottle (Residualized AES)\")\n",
    "display(resd_results_p3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ea1ca2",
   "metadata": {},
   "source": [
    "<h3>7. Store filtered_participants_dataset_with_aes_scores</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6d8d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "df = pd.read_csv('../../data/prolific_participants_dataset.csv')\n",
    "\n",
    "# save df\n",
    "df.to_csv('../../data/filtered_participants_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b219864-bbd5-4260-91c2-d33834bd9d2b",
   "metadata": {},
   "source": [
    "<h3>7. Compute Pearson Correaltions for Fisher's z test </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a209f9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "\n",
    "def compute_correlations_with_pvalues(df, aes_type='raw'):\n",
    "    # Big Five traits\n",
    "    traits_cols = [\n",
    "        'extraversion_score',\n",
    "        'agreeableness_score',\n",
    "        'conscientiousness_score',\n",
    "        'neuroticism_score',\n",
    "        'openness_score'\n",
    "    ]\n",
    "\n",
    "    # AES suffix\n",
    "    if aes_type == 'raw':\n",
    "        aes_suffix = 'aes'\n",
    "    elif aes_type == 'resd':\n",
    "        aes_suffix = 'aes_resd'\n",
    "    else:\n",
    "        raise ValueError(\"aes_type must be 'raw' or 'resd'.\")\n",
    "\n",
    "    # AES columns grouped by product\n",
    "    product_aes_cols = {\n",
    "        \"p1\": [f'{aes_suffix}_1_extraversion', f'{aes_suffix}_1_agreeableness',\n",
    "               f'{aes_suffix}_1_conscientiousness', f'{aes_suffix}_1_neuroticism', f'{aes_suffix}_1_openness'],\n",
    "        \"p2\": [f'{aes_suffix}_2_extraversion', f'{aes_suffix}_2_agreeableness',\n",
    "               f'{aes_suffix}_2_conscientiousness', f'{aes_suffix}_2_neuroticism', f'{aes_suffix}_2_openness'],\n",
    "        \"p3\": [f'{aes_suffix}_3_extraversion', f'{aes_suffix}_3_agreeableness',\n",
    "               f'{aes_suffix}_3_conscientiousness', f'{aes_suffix}_3_neuroticism', f'{aes_suffix}_3_openness']\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    p_vals = {}\n",
    "\n",
    "    for product, aes_cols in product_aes_cols.items():\n",
    "        correlation_results = pd.DataFrame(index=traits_cols, columns=aes_cols)\n",
    "\n",
    "        p_vals_product = []\n",
    "\n",
    "        for trait_col in traits_cols:\n",
    "            for aes_col in aes_cols:\n",
    "                corr_res = pg.corr(df[trait_col], df[aes_col])\n",
    "                correlation = corr_res[\"r\"].values[0]\n",
    "                p_value = corr_res[\"p-val\"].values[0]\n",
    "                correlation_results.loc[trait_col, aes_col] = f\"{correlation:.2f} (p={p_value:.6f})\"\n",
    "                p_vals_product.append(p_value)\n",
    "\n",
    "        results[product] = correlation_results\n",
    "        p_vals[product] = p_vals_product\n",
    "\n",
    "    return results, p_vals\n",
    "\n",
    "results, p_vals = compute_correlations_with_pvalues(df_filtered, aes_type='raw')\n",
    "\n",
    "\n",
    "# Display results\n",
    "print(\"Pearson Correlations with p-values - Product 1\")\n",
    "display(results[\"p1\"])\n",
    "print(\"Pearson Correlations with p-values - Product 2\")\n",
    "display(results[\"p2\"])\n",
    "print(\"Pearson Correlations with p-values - Product 3\")\n",
    "display(results[\"p3\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9514525d",
   "metadata": {},
   "source": [
    "<h3> 8. Store p-values for for p-val FDR correction</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4347dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "pvals = {\n",
    "    \"p1_human_correlatins_analysis\": p_vals[\"p1\"],\n",
    "    \"p2_human_correlatins_analysis\": p_vals[\"p2\"],\n",
    "    \"p3_human_correlatins_analysis\": p_vals[\"p3\"],\n",
    "}\n",
    "\n",
    "# save pvals\n",
    "with open(\"../p_value_correction/human_correlations_pvals.json\", \"w\") as f:\n",
    "    json.dump(pvals, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synthetic-twin-agents-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
